{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning (Logistic Regresion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path donde se encuentran mis archivos train\n",
    "BASE_PATH = \"./data/processed\"\n",
    "TRAIN_PATHS = [\n",
    "    \"X_train_con_outliers.xlsx\",\n",
    "    \"X_train_sin_outliers.xlsx\",\n",
    "    \"X_train_con_outliers_norm.xlsx\",\n",
    "    \"X_train_sin_outliers_norm.xlsx\",\n",
    "    \"X_train_con_outliers_scal.xlsx\",\n",
    "    \"X_train_sin_outliers_scal.xlsx\"\n",
    "]\n",
    "\n",
    "# Guardo cada uno de estos archivos dentro de una lista\n",
    "TRAIN_DATASETS = []\n",
    "for path in TRAIN_PATHS:\n",
    "    TRAIN_DATASETS.append(\n",
    "        # pd.read_excel(BASE_PATH + \"/\" + path)\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "        # pd.read_excel(os.path.join(BASE_PATH, path))\n",
    "    )\n",
    "\n",
    "# Path donde se encuentran mis archivos test\n",
    "TEST_PATHS = [\n",
    "    \"X_test_con_outliers.xlsx\",\n",
    "    \"X_test_sin_outliers.xlsx\",\n",
    "    \"X_test_con_outliers_norm.xlsx\",\n",
    "    \"X_test_sin_outliers_norm.xlsx\",\n",
    "    \"X_test_con_outliers_scal.xlsx\",\n",
    "    \"X_test_sin_outliers_scal.xlsx\"\n",
    "]\n",
    "\n",
    "# Guardo cada uno de estos archivos dentro de una lista\n",
    "TEST_DATASETS = []\n",
    "for path in TEST_PATHS:\n",
    "    TEST_DATASETS.append(\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "    )\n",
    "\n",
    "y_train = pd.read_excel(f\"{BASE_PATH}/y_train.xlsx\")\n",
    "y_test = pd.read_excel(f\"{BASE_PATH}/y_test.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': 0.7220637329286799, 'test': 0.7177713037144938},\n",
       " {'train': 0.7207587253414264, 'test': 0.7164360281621753},\n",
       " {'train': 0.7358421851289834, 'test': 0.7320951687302744},\n",
       " {'train': 0.7207890743550834, 'test': 0.7171643602816218},\n",
       " {'train': 0.7353869499241275, 'test': 0.7310026705511047},\n",
       " {'train': 0.7207890743550834, 'test': 0.7171643602816218}]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "for index, dataset in enumerate(TRAIN_DATASETS):\n",
    "    print(index)\n",
    "    model = LogisticRegression(random_state = 42, class_weight='balanced')\n",
    "    model.fit(dataset, y_train)\n",
    "    y_pred_train = model.predict(dataset)\n",
    "    y_pred_test = model.predict(TEST_DATASETS[index])\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"train\": accuracy_score(y_train, y_pred_train),\n",
    "            \"test\": accuracy_score(y_test, y_pred_test)\n",
    "        }\n",
    "    )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el que tiene una mayor precision es que tiene indice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero una buscado de manera aleatoria general para encontrar los mejores valores y optimizar sobre ellos posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "best_dataset = 2\n",
    "\n",
    "\n",
    "hyperparams_general = {\n",
    "    'C': np.logspace(-3, 3, 1000),          # Desde regularización muy fuerte hasta muy débil\n",
    "    'tol': np.linspace(0.0001, 0.01, 500),    # Rango amplio para el criterio de convergencia\n",
    "    'fit_intercept': [True, False],\n",
    "    'penalty': ['l1', 'l2'],                # Simplificamos a l1 y l2 para el ejemplo\n",
    "    'max_iter': [100, 500, 1000],\n",
    "    'solver': ['saga']                     # 'saga' es flexible y soporta ambas penalizaciones\n",
    "}\n",
    "\n",
    "model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "grid_general  = RandomizedSearchCV(model, hyperparams_general, n_iter=20, cv=10, scoring='f1', random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor score en RandomizedSearchCV: 0.37268205381915454\n",
      "Mejores parámetros encontrados: {'tol': np.float64(0.009702404809619238), 'solver': 'saga', 'penalty': 'l1', 'max_iter': 100, 'fit_intercept': True, 'C': np.float64(85.29644499741016)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "grid_general.fit(TRAIN_DATASETS[best_dataset], y_train)\n",
    "\n",
    "print(\"Mejor score en RandomizedSearchCV:\", grid_general.best_score_)\n",
    "print(\"Mejores parámetros encontrados:\", grid_general.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor score en GridSearchCV refinado: 0.37268205381915454\n",
      "Mejores parámetros refinados: {'C': np.float64(26.97310425070911), 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': np.float64(0.009202404809619237)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Extraemos los mejores parámetros de la búsqueda amplia\n",
    "best_params = grid_general.best_params_\n",
    "best_C = best_params[\"C\"]\n",
    "best_tol = best_params[\"tol\"]\n",
    "\n",
    "# Creamos un grid refinado en torno a los mejores valores encontrados\n",
    "# Por ejemplo, generamos 10 valores para C en un rango pequeño alrededor del óptimo\n",
    "C_range = np.logspace(np.log10(best_C) - 0.5, np.log10(best_C) + 0.5, 10)\n",
    "# Y para tol, usamos un rango lineal ajustado alrededor del valor óptimo\n",
    "tol_range = np.linspace(max(best_tol - 0.0005, 0.0001), best_tol + 0.0005, 10)\n",
    "\n",
    "# Creamos el grid refinado, fijando los demás parámetros al mejor encontrado\n",
    "hyperparams_optimizacion = {\n",
    "    'C': C_range,\n",
    "    'tol': tol_range,\n",
    "    'fit_intercept': [best_params['fit_intercept']],\n",
    "    'penalty': [best_params['penalty']],\n",
    "    'max_iter': [best_params['max_iter']],\n",
    "    'solver': [best_params['solver']]\n",
    "}\n",
    "\n",
    "# Configuramos GridSearchCV para refinar la búsqueda\n",
    "grid_optimized = GridSearchCV(model, hyperparams_optimizacion, cv=10, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Ajustamos el modelo con el grid refinado\n",
    "grid_optimized.fit(TRAIN_DATASETS[best_dataset], y_train)\n",
    "\n",
    "print(\"Mejor score en GridSearchCV refinado:\", grid_optimized.best_score_)\n",
    "print(\"Mejores parámetros refinados:\", grid_optimized.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "final_model = grid_optimized.best_estimator_\n",
    "y_pred_train = grid_optimized.predict(TRAIN_DATASETS[best_dataset])\n",
    "y_pred_test = grid_optimized.predict(TEST_DATASETS[best_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7356904400606981"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.8888922610015174\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "train_accuracy\n",
    "\n",
    "# 0.8889529590288315\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318523913571255"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.8860160233066279\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_accuracy\n",
    "\n",
    "# 0.8866229667394999\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dudas:\n",
    "\n",
    "- que hemos hecho con feature selection, no lo hemos usado?\n",
    "- Por que apenas obtengo mejoras y como puedo conseguir llegar al 0.9\n",
    "- Hay alguna manera de poder graficar la progresion de los hyperparametros cuando se calcula con un conjunto de estos? Lo que yo he hecho los calcula individualmente y no me da buen resultado\n",
    "- En cual de los valores me tengo que fijar?\n",
    "\n",
    "- He visto que en casos como estos en los que las clases estan desbalanceadas(muchos mas no que si), la metrica accuracy no es correcta y puede estar fallando y dando falsos positivos.\n",
    "Que otras metricas tendria que utilizar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7318523913571255\n",
      "Precision: 0.25175370226032734\n",
      "Recall: 0.6909090909090909\n",
      "F1 Score: 0.36903741788060557\n",
      "Confusion Matrix:\n",
      " [[5383 1920]\n",
      " [ 289  646]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Asumiendo que ya tienes y_test y y_pred (y_prob si calculas ROC AUC)\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "prec = precision_score(y_test, y_pred_test)\n",
    "rec = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7076960427288177\n",
      "Precision: 0.2374331550802139\n",
      "Recall: 0.7122994652406417\n",
      "F1 Score: 0.35614973262032085\n",
      "Confusion Matrix:\n",
      " [[5164 2139]\n",
      " [ 269  666]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = final_model.predict_proba(TEST_DATASETS[best_dataset])[:, 1]\n",
    "\n",
    "# Suponiendo que decidimos probar un umbral de 0.4 en lugar del 0.5\n",
    "umbral = 0.4\n",
    "y_pred_ajustado = (y_prob > umbral).astype(int)\n",
    "\n",
    "# Calculamos las métricas con el nuevo umbral\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ajustado))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_ajustado))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_ajustado))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_ajustado))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ajustado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "El modelo tiene un entrenamiento correcto, dependiendo del objetivo del negocio podemos cambiar el umbral de esta manera:\n",
    "\n",
    " - Con un umbral de 0.4, se detecta a más clientes (recall del 71%), pero la precisión cae a alrededor del 24%, lo que implica que se contactará a muchos clientes que no son realmente interesados. El F1 Score es ligeramente inferior al de la configuración por defecto(0.5).\n",
    "\n",
    " - Con un el umbral de 0.6, el modelo se vuelve más conservador. Esto eleva la precisión (más de 32% de las predicciones positivas son correctas) y mejora el F1 Score, pero reduce el recall a alrededor del 58%, lo que significa que se pierden algunos clientes potenciales.\n",
    "\n",
    " - Con el umbral por defecto se capturan aproximadamente el 69% de los verdaderos positivos, pero solo el 25% de los clientes contactados realmente son potenciales interesados.\n",
    "\n",
    "\n",
    "En principio la manera de captar mas clientes seria con un umbral del 0.4 ya que se contacta a muchos mas clientes, pero conlleva un mayor gasto economico ya que es menos preciso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
